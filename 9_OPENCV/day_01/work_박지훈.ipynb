{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "씐나는 과제 - 이미지 잘 찾는 모데루 만들기~  \n",
    "다중분류!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import torch       \n",
    "import torch.nn as nn              \n",
    "import torch.nn.functional as F \n",
    "from torch.utils.data import Dataset, DataLoader \n",
    "import torch.optim as optim    \n",
    "from torchmetrics.classification import F1Score, BinaryF1Score, BinaryAccuracy, Recall, MulticlassF1Score\n",
    "from torchmetrics.classification import BinaryConfusionMatrix\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt              \n",
    "from sklearn.preprocessing import * \n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 준비\n",
    "imgDF = pd.read_csv(r'C:\\Users\\hoon\\Desktop\\KDT 6\\EX_PANDAS6-main\\OPENCV\\data\\MNIST_train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=59999, step=1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터셋 정보 확인\n",
    "imgDF.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "타겟 : 1번 컬럼  \n",
    "피쳐 : 나머지 전부"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5        0\n",
       "0        0\n",
       "0.1      0\n",
       "0.2      0\n",
       "0.3      0\n",
       "        ..\n",
       "0.613    0\n",
       "0.614    0\n",
       "0.615    0\n",
       "0.616    0\n",
       "0.617    0\n",
       "Length: 785, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결측치 확인\n",
    "imgDF.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 피쳐와 타겟 분리\n",
    "featureDF = imgDF.iloc[:, 1:]  \n",
    "targetDF = imgDF[[imgDF.columns[0]]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델 구현 클래스 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class imgmodel(nn.Module) :\n",
    "    def __init__(self) :\n",
    "        super().__init__()\n",
    "        self.in_layer = nn.Linear(784,10)\n",
    "        self.h1_layer = nn.Linear(10,30)\n",
    "        self.h2_layer = nn.Linear(30,50)\n",
    "        self.h3_layer = nn.Linear(50,30)\n",
    "        self.h4_layer = nn.Linear(30,10)\n",
    "        self.out_layer = nn.Linear(10,10)\n",
    "\n",
    "    def forward(self,data) :\n",
    "        y = F.leaky_relu(self.in_layer(data))\n",
    "        \n",
    "        y = F.leaky_relu(self.h1_layer(y))\n",
    "        y = F.leaky_relu(self.h2_layer(y))\n",
    "        y = F.leaky_relu(self.h3_layer(y))\n",
    "        y = F.leaky_relu(self.h4_layer(y))\n",
    "\n",
    "        return self.out_layer(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imgmodel(\n",
      "  (in_layer): Linear(in_features=784, out_features=10, bias=True)\n",
      "  (h1_layer): Linear(in_features=10, out_features=30, bias=True)\n",
      "  (h2_layer): Linear(in_features=30, out_features=50, bias=True)\n",
      "  (h3_layer): Linear(in_features=50, out_features=30, bias=True)\n",
      "  (h4_layer): Linear(in_features=30, out_features=10, bias=True)\n",
      "  (out_layer): Linear(in_features=10, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 모델 인스턴스 생성\n",
    "model = imgmodel()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터셋 클래스 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class imgDataset(Dataset) :\n",
    "    def __init__(self,featureDF,targetDF) :\n",
    "        self.featureDF = featureDF\n",
    "        self.targetDF = targetDF\n",
    "        self.n_rows = featureDF.shape[0]\n",
    "        self.n_features = featureDF.shape[1]\n",
    "\n",
    "    def __len__(self) :\n",
    "        return self.n_rows\n",
    "    \n",
    "    def __getitem__(self,index) :\n",
    "        featureTS = torch.FloatTensor(self.featureDF.iloc[index].values)\n",
    "        targetTS = torch.FloatTensor(self.targetDF.iloc[index].values)\n",
    "\n",
    "        return featureTS, targetTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 커스텀 데이터셋 생성\n",
    "imgDS = imgDataset(featureDF,targetDF)\n",
    "\n",
    "# 데이터로더 인스턴스 생성\n",
    "imgDL = DataLoader(imgDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 30\n",
    "BATCH_SIZE = 3\n",
    "LR = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33749, 784) (15000, 784) (11250, 784)\n",
      "(33749, 1) (15000, 1) (11250, 1)\n",
      "5\n",
      "1    3810\n",
      "7    3531\n",
      "3    3421\n",
      "9    3352\n",
      "0    3347\n",
      "6    3342\n",
      "4    3308\n",
      "2    3300\n",
      "8    3271\n",
      "5    3067\n",
      "Name: count, dtype: int64 5\n",
      "1    1650\n",
      "7    1564\n",
      "3    1531\n",
      "2    1527\n",
      "8    1503\n",
      "0    1474\n",
      "6    1468\n",
      "4    1458\n",
      "9    1452\n",
      "5    1373\n",
      "Name: count, dtype: int64 5\n",
      "1    1282\n",
      "3    1179\n",
      "7    1170\n",
      "9    1145\n",
      "2    1131\n",
      "6    1108\n",
      "0    1102\n",
      "8    1077\n",
      "4    1076\n",
      "5     980\n",
      "Name: count, dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'pandas.core.frame.DataFrame'> <class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# 학습용, 검증용 데이터셋 생성\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(featureDF,targetDF,\n",
    "                                                    random_state=1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train,y_train,\n",
    "                                                  random_state=1)\n",
    "\n",
    "\n",
    "print(f'{X_train.shape} {X_test.shape} {X_val.shape}')\n",
    "print(f'{y_train.shape} {y_test.shape} {y_val.shape}')\n",
    "print(f'{y_train.value_counts()} {y_test.value_counts()} {y_val.value_counts()}')\n",
    "print(f'{type(X_train)} {type(X_test)} {type(X_val)}')\n",
    "\n",
    "trainDS = imgDataset(X_train,y_train)\n",
    "valDS = imgDataset(X_val,y_val)\n",
    "testDS = imgDataset(X_test,y_test)\n",
    "\n",
    "# 각 데이터로더 생성\n",
    "trainDL = DataLoader(trainDS, batch_size=BATCH_SIZE)\n",
    "valDL = DataLoader(valDS, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최적화 준비\n",
    "optimizer = optim.Adam(model.parameters(),lr=LR)\n",
    "\n",
    "crossLoss = nn.CrossEntropyLoss()\n",
    "\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode = 'max', patience=30 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/30]\n",
      "- [TRAIN] LOSS : 0.6221491021127616 SCORE : 0.7375629662116369\n",
      "- [VALID] LOSS : 0.39784306287765503 SCORE : 0.8879976272583008\n",
      "[1/30]\n",
      "- [TRAIN] LOSS : 0.3673663472003261 SCORE : 0.8577629653573036\n",
      "- [VALID] LOSS : 0.3707354962825775 SCORE : 0.900248110294342\n",
      "[2/30]\n",
      "- [TRAIN] LOSS : 0.3248045515329052 SCORE : 0.8745560514940156\n",
      "- [VALID] LOSS : 0.34500065445899963 SCORE : 0.9017664194107056\n",
      "[3/30]\n",
      "- [TRAIN] LOSS : 0.3010347296017016 SCORE : 0.882792100807031\n",
      "- [VALID] LOSS : 0.3076452910900116 SCORE : 0.9162353277206421\n",
      "[4/30]\n",
      "- [TRAIN] LOSS : 0.28510613183922784 SCORE : 0.8875886439469125\n",
      "- [VALID] LOSS : 0.32651111483573914 SCORE : 0.9138574004173279\n",
      "[5/30]\n",
      "- [TRAIN] LOSS : 0.2740981870759451 SCORE : 0.891116545135445\n",
      "- [VALID] LOSS : 0.311529278755188 SCORE : 0.9164637923240662\n",
      "[6/30]\n",
      "- [TRAIN] LOSS : 0.26628924742223065 SCORE : 0.8931575327224202\n",
      "- [VALID] LOSS : 0.3601195216178894 SCORE : 0.9083243608474731\n",
      "[7/30]\n",
      "- [TRAIN] LOSS : 0.25909027818513647 SCORE : 0.8961841993702783\n",
      "- [VALID] LOSS : 0.32338014245033264 SCORE : 0.9165449738502502\n",
      "[8/30]\n",
      "- [TRAIN] LOSS : 0.2558382357143496 SCORE : 0.9002725943260723\n",
      "- [VALID] LOSS : 0.29788482189178467 SCORE : 0.9206757545471191\n",
      "[9/30]\n",
      "- [TRAIN] LOSS : 0.2450550457562134 SCORE : 0.9041041992213991\n",
      "- [VALID] LOSS : 0.31351375579833984 SCORE : 0.9094506502151489\n",
      "[10/30]\n",
      "- [TRAIN] LOSS : 0.24339966868825988 SCORE : 0.9043792609519429\n",
      "- [VALID] LOSS : 0.32479700446128845 SCORE : 0.9180042743682861\n",
      "[11/30]\n",
      "- [TRAIN] LOSS : 0.2375738260725552 SCORE : 0.907979260898961\n",
      "- [VALID] LOSS : 0.29679641127586365 SCORE : 0.9244424104690552\n",
      "[12/30]\n",
      "- [TRAIN] LOSS : 0.2399525647719499 SCORE : 0.9081906188885371\n",
      "- [VALID] LOSS : 0.30346181988716125 SCORE : 0.9195498824119568\n",
      "[13/30]\n",
      "- [TRAIN] LOSS : 0.23201366653946756 SCORE : 0.9080207423713472\n",
      "- [VALID] LOSS : 0.29212164878845215 SCORE : 0.9262720346450806\n",
      "[14/30]\n",
      "- [TRAIN] LOSS : 0.23318201435709254 SCORE : 0.9110034583979183\n",
      "- [VALID] LOSS : 0.33158788084983826 SCORE : 0.9143622517585754\n",
      "[15/30]\n",
      "- [TRAIN] LOSS : 0.22535158105503594 SCORE : 0.9089921003845003\n",
      "- [VALID] LOSS : 0.40814265608787537 SCORE : 0.9000163078308105\n",
      "[16/30]\n",
      "- [TRAIN] LOSS : 0.22376128074799687 SCORE : 0.9117990139259232\n",
      "- [VALID] LOSS : 0.32366979122161865 SCORE : 0.9224004745483398\n",
      "[17/30]\n",
      "- [TRAIN] LOSS : 0.2197464730880778 SCORE : 0.912550618798203\n",
      "- [VALID] LOSS : 0.4233620762825012 SCORE : 0.923448920249939\n",
      "[18/30]\n",
      "- [TRAIN] LOSS : 0.2155041472683432 SCORE : 0.9159925941268603\n",
      "- [VALID] LOSS : 0.42430946230888367 SCORE : 0.9061596393585205\n",
      "[19/30]\n",
      "- [TRAIN] LOSS : 0.2199519179766467 SCORE : 0.915007902791765\n",
      "- [VALID] LOSS : 0.329282283782959 SCORE : 0.9232117533683777\n",
      "[20/30]\n",
      "- [TRAIN] LOSS : 0.2028176216346544 SCORE : 0.9181481496228112\n",
      "- [VALID] LOSS : 0.3067176043987274 SCORE : 0.9261650443077087\n",
      "[21/30]\n",
      "- [TRAIN] LOSS : 0.2151457029796348 SCORE : 0.9145985200630294\n",
      "- [VALID] LOSS : 0.2931467294692993 SCORE : 0.9308937191963196\n",
      "[22/30]\n",
      "- [TRAIN] LOSS : 0.20952257483194653 SCORE : 0.915939260840416\n",
      "- [VALID] LOSS : 0.33099472522735596 SCORE : 0.9193938970565796\n"
     ]
    }
   ],
   "source": [
    "## 학습의 효과 확인을 위해 손실값과 성능평가값 저장 필요\n",
    "LOSS_HISTORY, SCORE_HISTORY = [[],[]],[[],[]]\n",
    "CNT = len(trainDL)\n",
    "\n",
    "## 학습 모니터링/스케줄링 설정 \n",
    "# => LOSS_HISTORY, SCORE_HISTROY 활용\n",
    "# => 임계기준 : 10번\n",
    "BREAK_CNT = 0\n",
    "\n",
    "for epoch in range(EPOCH) :\n",
    "    # 학습 모드로 모델 설정\n",
    "    model.train()\n",
    "\n",
    "\n",
    "    # 배치크기만큼 데이터 로딩해서 학습 진행\n",
    "    loss_total , score_total = 0, 0\n",
    "    for featureTS, targetTS in trainDL :\n",
    "        \n",
    "        # 학습 진행\n",
    "        pre_y = model(featureTS)\n",
    "\n",
    "        # 손실 계산 : nn.CrossEntropyLoss 요구사항 : 정답/타겟은 0D 또는 1D, 타입은 long\n",
    "        loss = crossLoss(pre_y,targetTS.reshape(-1).long())\n",
    "        loss_total += loss.item()\n",
    "\n",
    "        # 성능 평가 계산\n",
    "        score = MulticlassF1Score(num_classes=10)(pre_y,targetTS.reshape(-1))\n",
    "        score_total += score.item()\n",
    "\n",
    "        # 최적화 진행\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # 에포크 당 검증기능\n",
    "    # 모델 검증 모드 설정\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # 검증 데이터셋\n",
    "        val_featureTS = torch.FloatTensor(valDS.featureDF.values)\n",
    "        val_targetTS = torch.FloatTensor(valDS.targetDF.values)\n",
    "        # 추론/평가\n",
    "        pre_val = model(val_featureTS)\n",
    "        # 손실계산\n",
    "        loss_val = crossLoss(pre_val, val_targetTS.reshape(-1).long())\n",
    "        # 성능평가\n",
    "        score_val = MulticlassF1Score(num_classes=10)(pre_val, val_targetTS.reshape(-1))\n",
    "\n",
    "\n",
    "    # 손실값과 성능평가값 저장\n",
    "    LOSS_HISTORY[0].append(loss_total/CNT) \n",
    "    SCORE_HISTORY[0].append(score_total/CNT)\n",
    "    LOSS_HISTORY[1].append(loss_val) \n",
    "    SCORE_HISTORY[1].append(score_val)  \n",
    "\n",
    "    print(f'[{epoch}/{EPOCH}]\\n- [TRAIN] LOSS : {LOSS_HISTORY[0][-1]} SCORE : {SCORE_HISTORY[0][-1]}')\n",
    "    print(f'- [VALID] LOSS : {LOSS_HISTORY[1][-1]} SCORE : {SCORE_HISTORY[1][-1]}')\n",
    "\n",
    "    scheduler.step(score_val)\n",
    "\n",
    "    if scheduler.num_bad_epochs >= scheduler.patience :\n",
    "        print(f'{scheduler.patience} EPCOH 성능 개선이 없어서 조기종료')\n",
    "        break   \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OPENCV_38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
