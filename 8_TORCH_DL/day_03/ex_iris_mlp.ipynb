{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iris 데이터셋 활용해서 꽃잎 너비 예측 모델\n",
    " - 데이터셋 : iris.csv에서 2개의 Feature 사용\n",
    " - 구현프레임워크 : Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [1] 모듈 로딩 및 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모듈 로딩\n",
    "import torch                                    # 텐서 및 수치 계산 함수 관련 모듈\n",
    "import torch.nn as nn                           # 인공신경망 관련 모듈\n",
    "import torch.nn.functional as F                 # 손실, 거래 등 함수 관련 모듈 \n",
    "import torch.optim as optimizer                 # 최적화 기법 관련 모듈\n",
    "from torchmetrics.regression import R2Score     # 성능지표 관련 모듈   - 추가 설치\n",
    "from torchinfo import summary                   # 모델 정보 관련 모듈  - 추가 설치\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import  train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE => cpu\n"
     ]
    }
   ],
   "source": [
    "# 모델의 가중치 및 절편 값 고정 설정\n",
    "torch.manual_seed(1)\n",
    "\n",
    "# 저장 및 실행 위치 설정\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print(f'DEVICE => {DEVICE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal.length</th>\n",
       "      <th>sepal.width</th>\n",
       "      <th>petal.length</th>\n",
       "      <th>petal.width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal.length  sepal.width  petal.length  petal.width\n",
       "0           5.1          3.5           1.4          0.2\n",
       "1           4.9          3.0           1.4          0.2\n",
       "2           4.7          3.2           1.3          0.2\n",
       "3           4.6          3.1           1.5          0.2\n",
       "4           5.0          3.6           1.4          0.2"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [1-1] 데이터 로딩\n",
    "irisDF = pd.read_csv(r'C:\\Users\\KDP-17\\EX_PANDAS6\\TORCH_DL\\data\\iris.csv',usecols=[0,1,2,3])\n",
    "irisDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[2] 모델 준비\n",
    " - 학습방법 : 지도학습 > 회귀\n",
    " - 알고리즘 : 선형관계 >> 선형모델 ==> nn.Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n입력층의 입력은 피쳐 개수로 고정\\n출력층의 출력은 타겟 개수로 고정\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 설계\n",
    "# 입력층에 입력값(feature)  => sepal.length, sepal.width, petal.length 3개\n",
    "# 출력층에 출력값(target) => petal.width 1개\n",
    "# 입력층 : 입력 피쳐 3개, 출력 입력층에 존재하는 퍼셉트론 개수 10개, AF - ReLU\n",
    "#                                                      ㅣ     \n",
    "#            -------------------------------------------\n",
    "#           ㅣ\n",
    "# 은닉층 : 입력 10개, 출력 입력층에 존재하는 퍼셉트론 개수 5개, AF - ReLU\n",
    "#                                                       ㅣ\n",
    "#                ----------------------------------------\n",
    "#               ㅣ\n",
    "# 출력층 : 입력 5개, 출력 타겟/라벨 개수 : 1개, AF - None\n",
    "\n",
    "model = nn.Sequential(nn.Linear(3,10),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(10,5),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(5,1))\n",
    "\n",
    "'''\n",
    "입력층의 입력은 피쳐 개수로 고정\n",
    "출력층의 출력은 타겟 개수로 고정\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=3, out_features=10, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=10, out_features=5, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=5, out_features=1, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Sequential                               [2000, 1]                 --\n",
       "├─Linear: 1-1                            [2000, 10]                40\n",
       "├─ReLU: 1-2                              [2000, 10]                --\n",
       "├─Linear: 1-3                            [2000, 5]                 55\n",
       "├─ReLU: 1-4                              [2000, 5]                 --\n",
       "├─Linear: 1-5                            [2000, 1]                 6\n",
       "==========================================================================================\n",
       "Total params: 101\n",
       "Trainable params: 101\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 0.20\n",
       "==========================================================================================\n",
       "Input size (MB): 0.02\n",
       "Forward/backward pass size (MB): 0.26\n",
       "Params size (MB): 0.00\n",
       "Estimated Total Size (MB): 0.28\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 구조 확인\n",
    "'''\n",
    "Param 개개수는 (입력 개수 + 1) * 퍼셉트론 개수\n",
    "'''\n",
    "print(model)\n",
    "summary(model,input_size=(2000,3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.weight], [Parameter containing:\n",
      "tensor([[ 0.2975, -0.2548, -0.1119],\n",
      "        [ 0.2710, -0.5435,  0.3462],\n",
      "        [-0.1188,  0.2937,  0.0803],\n",
      "        [-0.0707,  0.1601,  0.0285],\n",
      "        [ 0.2109, -0.2250, -0.0421],\n",
      "        [-0.0520,  0.0837, -0.0023],\n",
      "        [ 0.5047,  0.1797, -0.2150],\n",
      "        [-0.3487, -0.0968, -0.2490],\n",
      "        [-0.1850,  0.0276,  0.3442],\n",
      "        [ 0.3138, -0.5644,  0.3579]], requires_grad=True)],\"\n",
      "\"\n",
      "[0.bias], [Parameter containing:\n",
      "tensor([ 0.1613,  0.5476,  0.3811, -0.5260, -0.5489, -0.2785,  0.5070, -0.0962,\n",
      "         0.2471, -0.2683], requires_grad=True)],\"\n",
      "\"\n",
      "[2.weight], [Parameter containing:\n",
      "tensor([[ 0.3103, -0.1338,  0.2371,  0.0037, -0.1666,  0.1625, -0.1679,  0.0930,\n",
      "         -0.0913, -0.0347],\n",
      "        [-0.3040, -0.1508,  0.1716, -0.0769,  0.3150,  0.2535, -0.0148, -0.2111,\n",
      "          0.1926,  0.0981],\n",
      "        [-0.2044,  0.2054,  0.1920,  0.2805, -0.1773, -0.0521, -0.0061,  0.0462,\n",
      "         -0.2400, -0.2244],\n",
      "        [ 0.1720, -0.0742,  0.1545,  0.0180,  0.1038,  0.0695,  0.1150,  0.1568,\n",
      "         -0.2929,  0.1592],\n",
      "        [-0.2223, -0.2386,  0.0192, -0.0539,  0.1857, -0.1831, -0.2811,  0.2301,\n",
      "         -0.0469,  0.1779]], requires_grad=True)],\"\n",
      "\"\n",
      "[2.bias], [Parameter containing:\n",
      "tensor([ 0.1017, -0.2371,  0.0635,  0.0760, -0.2117], requires_grad=True)],\"\n",
      "\"\n",
      "[4.weight], [Parameter containing:\n",
      "tensor([[-0.2122,  0.1525,  0.0801, -0.1902, -0.1354]], requires_grad=True)],\"\n",
      "\"\n",
      "[4.bias], [Parameter containing:\n",
      "tensor([0.4096], requires_grad=True)],\"\n",
      "\"\n"
     ]
    }
   ],
   "source": [
    "# 가중치와 절편 확인\n",
    "for name, name_parameter in model.named_parameters() :\n",
    "    print(f'[{name}], [{name_parameter}],\"\\n\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[3] 최적화 인스턴스 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 모델의 가중치와 절편 최적화 이후 인스턴스에 전달\n",
    "adam_optimizer = optimizer.Adam(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[4] 학습 진행  ==> 개발자가 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - [4-1] 데이터셋 Tensor화 진행 : 데이터 준비 시 진행 or 학습 전 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sepal.length', 'sepal.width', 'petal.length'], dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irisDF.columns[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "featureDF.shape : (150, 3), targetDF.shape : (150, 1)\n"
     ]
    }
   ],
   "source": [
    "# 피쳐와 타겟 분리\n",
    "featureDF = irisDF[irisDF.columns[:-1]]\n",
    "targetDF = irisDF[['petal.width']]\n",
    "\n",
    "print(f'featureDF.shape : {featureDF.shape}, targetDF.shape : {targetDF.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train, Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(featureDF,targetDF,\n",
    "                                                   test_size = 0.2,\n",
    "                                                   random_state=5)\n",
    "\n",
    "# Train, Valid\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train,\n",
    "                                                   test_size = 0.2,\n",
    "                                                   random_state=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [4-2] 학습진행 : \n",
    "   * 학습횟수 결정 ==> 에포크 설정\n",
    "   * 배치 크기 결정\n",
    "   * 배치 개수 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH:1  BATCH_SIZE : 12  BATCH_CNT : 8\n"
     ]
    }
   ],
   "source": [
    "EPOCH = 1                                   # 처음 ~ 끝까지 공부하는 횟수\n",
    "BATCH_SIZE = 12                             # 1에포크에서 한번 학습할 분량 크기\n",
    "\n",
    "BATCH_CNT = X_train.shape[0]//BATCH_SIZE    # 1에포크에서 총 학습 횟수, 가중치 업데이트 횟수\n",
    "\n",
    "print(f'EPOCH:{EPOCH}  BATCH_SIZE : {BATCH_SIZE}  BATCH_CNT : {BATCH_CNT}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 테스트/검증 함수 \n",
    "# ==> 가중치,절편 업데이트 X 그래서 최적화 미진행 해야함\n",
    "# ==> 현재 가중치와 절편으로 테스트 진행\n",
    "def testing(testDF, targetDF, kind = 'Val') :\n",
    "\n",
    "    # Tensor 화\n",
    "    testTS = torch.FloatTensor(testDF.values).to(DEVICE)\n",
    "    targetTS = torch.FloatTensor(targetDF.values).to(DEVICE)\n",
    "    with torch.no_grad() :      # 가중치 및 절편 업데이트 X\n",
    "        # (1) 학습진행 forward\n",
    "        pre_y = model(testTS)\n",
    "\n",
    "        # (2) 오차계산 - 손실함수\n",
    "        loss = F.mse_loss(pre_y, targetTS)\n",
    "\n",
    "        # (3) 성능평가 - R2\n",
    "        r2 = R2Score()(pre_y,targetTS)\n",
    "       \n",
    "        # (4) 학습 과정 출력\n",
    "        print(f'[{kind}] LOSS : {loss} R2 : {r2}   ')\n",
    "\n",
    "    return loss, r2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습 함수\n",
    "def training(featureTS, targetTS, valTS, valTargetTS) :\n",
    "    #[[],[]] <= [train, val]\n",
    "    loss_history = [[],[]]\n",
    "    r2_history = [[],[]]\n",
    "\n",
    "    for epoch in range(EPOCH) : \n",
    "        # 배치 손실 저장 변수\n",
    "        bs_loss,bs_r2 = 0,0\n",
    "        # 배치 크기만큼 학습 진행\n",
    "        for i in range(BATCH_CNT) :\n",
    "            start = i*BATCH_SIZE\n",
    "            end = start + BATCH_SIZE\n",
    "            \n",
    "            \n",
    "            # BATCH_SIZE 크기만큼만 데이터 추출해서 Tensor화 진행\n",
    "            BSX_train = torch.FloatTensor(X_train[start:end].values).to(DEVICE)\n",
    "            BSy_train = torch.FloatTensor(y_train[start:end].values).to(DEVICE)\n",
    "            print(BSX_train.shape, BSX_train.device, BSX_train.dtype)\n",
    "            print(BSy_train.shape, BSy_train.device, BSy_train.dtype)\n",
    "            print()\n",
    "\n",
    "        # (1) 학습진행 forward\n",
    "        pre_y = model(BSX_train)\n",
    "\n",
    "        # (2) 오차계산 - 손실함수\n",
    "        loss = F.mse_loss(pre_y, BSy_train)\n",
    "        bs_loss += loss.item()\n",
    "        bs_r2 += R2Score()(pre_y,BSy_train).item()\n",
    "       \n",
    "        # (3) 최적화 - 가중치, 절편 업데이트\n",
    "        adam_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        adam_optimizer.step()\n",
    "\n",
    "    val_loss, val_r2 = testing(valTS,valTargetTS)\n",
    "    loss_history[1].append(val_loss.item())\n",
    "    r2_history[1].append(val_r2.item())\n",
    "\n",
    "    # 에포크 단위 손실과 성능지표(r2)\n",
    "    loss_history[0].append(bs_loss/BATCH_CNT)\n",
    "    r2_history[0].append(bs_r2/BATCH_CNT)\n",
    "\n",
    "\n",
    "    # (4) 학습 과정 출력\n",
    "    print(f'[{epoch}/{EPOCH}] TRAIN_LOSS : {loss_history[0]}  R2 : {r2_history[0][-1]}')\n",
    "    print(f'VALID LOSS : {loss_history[1][-1]}  R2 : {r2_history[1][-1]}')\n",
    "\n",
    "    return loss_history, r2_history "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 3]) cpu torch.float32\n",
      "torch.Size([12, 1]) cpu torch.float32\n",
      "\n",
      "torch.Size([12, 3]) cpu torch.float32\n",
      "torch.Size([12, 1]) cpu torch.float32\n",
      "\n",
      "torch.Size([12, 3]) cpu torch.float32\n",
      "torch.Size([12, 1]) cpu torch.float32\n",
      "\n",
      "torch.Size([12, 3]) cpu torch.float32\n",
      "torch.Size([12, 1]) cpu torch.float32\n",
      "\n",
      "torch.Size([12, 3]) cpu torch.float32\n",
      "torch.Size([12, 1]) cpu torch.float32\n",
      "\n",
      "torch.Size([12, 3]) cpu torch.float32\n",
      "torch.Size([12, 1]) cpu torch.float32\n",
      "\n",
      "torch.Size([12, 3]) cpu torch.float32\n",
      "torch.Size([12, 1]) cpu torch.float32\n",
      "\n",
      "torch.Size([12, 3]) cpu torch.float32\n",
      "torch.Size([12, 1]) cpu torch.float32\n",
      "\n",
      "[Val] LOSS : 0.5848502516746521 R2 : -0.4013630151748657   \n",
      "[0/1] TRAIN_LOSS : [0.11050643771886826]  R2 : -0.19764670729637146\n",
      "VALID LOSS : 0.5848502516746521  R2 : -0.4013630151748657\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([[0.11050643771886826], [0.5848502516746521]],\n",
       " [[-0.19764670729637146], [-0.4013630151748657]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 학습 진행\n",
    "training(X_train,y_train,X_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 학습 후 loss 시각화\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m101\u001b[39m),\u001b[43mloss\u001b[49m[\u001b[38;5;241m0\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m101\u001b[39m),loss[\u001b[38;5;241m1\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVal\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain & Valid\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'loss' is not defined"
     ]
    }
   ],
   "source": [
    "# # 학습 후 loss 시각화\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.plot(range(1,101),loss[0], label='Train')\n",
    "# plt.plot(range(1,101),loss[1], label=-'Val')\n",
    "# plt.title('Train & Valid')\n",
    "# plt.grid()\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TORCH_38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
