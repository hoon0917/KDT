{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DNN기반 다중분류 모델 구현\n",
    " - 데이터셋 : iris.csv\n",
    " - feature : 4개 Sepal_Length, Sepal_Width, Petal_Length, Petal_Width\n",
    " - target/label : 1개 variety\n",
    " - 학습방법 : 지도학습 > 분류 > 다중분류 (클래스 3개)\n",
    " - 알고리즘 : 인공신경망(ANN) -> MLP, DNN : 은닉층이 많은 구성\n",
    " - 프레임워크 : Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] 모듈 로딩 및 데이터 준비\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - 모델 관련\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from torchmetrics.classification import MulticlassF1Score\n",
    "from torchinfo import summary\n",
    "\n",
    "# - 데이터 관련\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 활용 패키지 버전 체크  ==> 사용자 정의 함수로 구현해놓기\n",
    "def checkversion() :\n",
    "    print(f'Pytorch v {torch.__version__}')\n",
    "    print(f'pandas v {pd.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal.length</th>\n",
       "      <th>sepal.width</th>\n",
       "      <th>petal.length</th>\n",
       "      <th>petal.width</th>\n",
       "      <th>variety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal.length  sepal.width  petal.length  petal.width variety\n",
       "0           5.1          3.5           1.4          0.2  Setosa\n",
       "1           4.9          3.0           1.4          0.2  Setosa"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### 데이터 로딩\n",
    "irisDF = pd.read_csv(r'C:\\Users\\hoon\\Desktop\\경대 KDT 6기\\EX_PANDAS6-main\\EX_PANDAS6-main\\TORCH_DL\\data\\iris.csv')\n",
    "irisDF.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels => {'Setosa': 0, 'Versicolor': 1, 'Virginica': 2}\n"
     ]
    }
   ],
   "source": [
    "### 타겟 변경 ==> 정수화, 클래스3개 => 2개\n",
    "labels = dict(zip(irisDF['variety'].unique().tolist(),range(3)))\n",
    "print(f'labels => {labels}')\n",
    "\n",
    "irisDF['variety'] = irisDF['variety'].replace(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[2] 모델 클래스 설계 및 정의<hr>\n",
    " - 클래스 목적 : iris 데이터 학습 및 추론\n",
    " - 클래스 이름 : IrisMCFModel\n",
    " - 부모 클래스 : nn.Module\n",
    " - 매개변수    : 층별 입/출력 개수 고정 => 매개변수 필요 없음 \n",
    " - 속성/필드   :  \n",
    " - 클래스 기능 : _ _ init _ _() : 모델 구조 설정, forward() : 순방향 학습  <= 오버라이딩(overriding)\n",
    " - 클래스 구조 \n",
    "   * 입력층 : 입력 4개     출력 10개 (퍼셉트론 10개 존재)\n",
    "   * 은닉층 : 입력 10개    출력 5개  (퍼셉트론 5개 존재)\n",
    "   * 출력층 : 입력 5개     출력 1개 (다중분류)\n",
    "\n",
    " - 활성화함수\n",
    "   * 클래스 형태 ==> nn.MELoss, nn.ReLU  -> _ _ init _ _() 메서드에서 사용\n",
    "   * 함수 형태  ==> torch.nn.functional 아래에 -> forward() 메서드에서 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class irisMCFModel(nn.Module) :\n",
    "\n",
    "    # 모델 구조 구성 및 인스턴스 생성 메서드\n",
    "    def __init__(self) :\n",
    "        super().__init__()\n",
    "        self.in_layer = nn.Linear(4,10)\n",
    "        self.h_layer = nn.Linear(10,5)\n",
    "        self.out_layer = nn.Linear(5,3)     # 다중분류 'Setosa', 'Ver', 'Vir'\n",
    "\n",
    "    # 순방향 학습 진행 메서드\n",
    "    def forward(self, data) :\n",
    "        # 입력층\n",
    "        y = self.in_layer(data)             # f1w1+f2w2+f3w3+...+f10w10+b\n",
    "        F.relu(y)                           # relu => y 값의 범위 : 0 < y\n",
    "        \n",
    "        # 은닉층 : 10개의 숫자값이 들어옴(>=0)\n",
    "        y = self.h_layer(y)\n",
    "        F.relu(y)\n",
    "\n",
    "        # 출력층 : 5개의 숫자 값 => 다중분류 : 손실함수 crossEntropyLoss 내부에서 Softmax 처리 해서 pytorch에서는 안넣어도 됨\n",
    "        return self.out_layer(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "irisMCFModel(\n",
      "  (in_layer): Linear(in_features=4, out_features=10, bias=True)\n",
      "  (h_layer): Linear(in_features=10, out_features=5, bias=True)\n",
      "  (out_layer): Linear(in_features=5, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "### 모델 인스턴스 생성\n",
    "model = irisMCFModel()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "irisMCFModel                             [10, 3]                   --\n",
       "├─Linear: 1-1                            [10, 10]                  50\n",
       "├─Linear: 1-2                            [10, 5]                   55\n",
       "├─Linear: 1-3                            [10, 3]                   18\n",
       "==========================================================================================\n",
       "Total params: 123\n",
       "Trainable params: 123\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 0.00\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.00\n",
       "Params size (MB): 0.00\n",
       "Estimated Total Size (MB): 0.00\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### [테스트] 모델 사용 메모리 정보 확인\n",
    "summary(model, input_size=(10,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[3] 데이터셋 클래스 설계 및 정의 <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IrisDataset(Dataset) :\n",
    "\n",
    "    def __init__(self,featureDF, targetDF) :\n",
    "        self.featureDF = featureDF\n",
    "        self.targetDF = targetDF\n",
    "        self.n_rows = featureDF.shape[0]\n",
    "        self.n_features = featureDF.shape[1]\n",
    "\n",
    "    def __len__(self) :\n",
    "        return self.n_rows\n",
    "\n",
    "    def __getitem__(self, index) :\n",
    "        \n",
    "        # 텐서화\n",
    "        featureTS = torch.FloatTensor(self.featureDF.iloc[index].values)\n",
    "        targetTS = torch.FloatTensor(self.targetDF.iloc[index].values)\n",
    "\n",
    "        # 피쳐와 타겟 반환\n",
    "        return featureTS, targetTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4]) torch.Size([1, 1])\n"
     ]
    }
   ],
   "source": [
    "## [테스트] 데이터셋 인스턴스 생성\n",
    "\n",
    "# - DataFrame에서 피쳐와 타겟 추출\n",
    "featureDF = irisDF[irisDF.columns[:-1]]\n",
    "targetDF = irisDF[irisDF.columns[-1:]]\n",
    "\n",
    "\n",
    "# - 커스텀 데이터셋 인스턴스 생성\n",
    "irisDS = IrisDataset(featureDF,targetDF)\n",
    "\n",
    "# - 데이터로더 인스턴스 생성        <= DataLoader로 테스트 해야함 for문으로 feature랑 label 하나씩 뽑아서 확인하믄 됨\n",
    "irisDL = DataLoader(irisDS)\n",
    "for feature, label in irisDL :\n",
    "    print(feature.shape, label.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[4] 학습 준비 <hr>\n",
    " - 학습횟수 : EPOCH          <- 처음 ~ 끝까지 공부하는 단위  \n",
    " - 배치크기 : BATCH_SIZE     <- 한번에 학습할 데이터 양\n",
    " - 위치지정 : DEVICE         <- 텐서 저장 및 실행 위치 (GPU/CPU)\n",
    " - 학습률(lr) : 가중치와 절편 업데이트 시 경사하강법으로 업데이트 간격 설정 (0.001 ~ 0.1) <- 하이퍼파라미터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 학습 진행 관련 설정값\n",
    "EPOCH = 1000\n",
    "BATCH_SIZE = 10\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "LR = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - 학습 준비에 필요한 것\n",
    "    * 인스턴스/객체 : 모델, 데이터셋, 최적화, (, 손실함수, 성능지표)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 찐 모델 인스턴스 생성\n",
    "model = irisMCFModel()\n",
    "\n",
    "# - 학습용, 검증용, 테스트용 데이터셋 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(featureDF,targetDF,random_state = 1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train,y_train,random_state = 1)\n",
    "\n",
    "# - 학습용, 검증용, 테스트용 인스턴스 생성\n",
    "trainDS = IrisDataset(X_train,y_train)\n",
    "valDS = IrisDataset(X_val,y_val)\n",
    "testDS = IrisDataset(X_test, y_test)\n",
    "\n",
    "# - 학습용 데이터로더 인스턴스 생성\n",
    "trainDL = DataLoader(trainDS,batch_size=BATCH_SIZE)\n",
    "\n",
    "# 최적화 인스턴스 - 최소의 손실을 만드는 w,b 찾는 작업 해주는 인스턴스\n",
    "# 최적화 인스턴스에 model.parameters() 전달 필요\n",
    "optimizer = optim.Adam(model.parameters(),lr=LR)\n",
    "\n",
    "\n",
    "# 손실함수 인스턴스 > 분류 > 다중분류 CrossEntropyLoss  \n",
    "#                                  예측값은 선형식 결과값으로 전달 \n",
    "crossLoss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[5] 학습 진행<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 학습의 효과 확인을 위해 손실값과 성능평가값 저장 필요\n",
    "LOSS_HISTORY, SCORE_HISTORY = [[],[]],[[],[]]\n",
    "CNT = len(trainDL)\n",
    "\n",
    "for epoch in range(EPOCH) :\n",
    "    # 학습 모드로 모델 설정\n",
    "    model.train()\n",
    "\n",
    "\n",
    "    # 배치크기만큼 데이터 로딩해서 학습 진행\n",
    "    loss_total , score_total = 0, 0\n",
    "    for featureTS, targetTS in trainDL :\n",
    "        \n",
    "        # 학습 진행\n",
    "        pre_y = model(featureTS)\n",
    "\n",
    "        # 손실 계산 : nn.CrossEntropyLoss 요구사항 : 정답/타겟은 0D 또는 1D, 타입은 long\n",
    "        loss = crossLoss(pre_y,targetTS.reshape(-1).long())\n",
    "        loss_total += loss.item()\n",
    "\n",
    "        # 성능 평가 계산\n",
    "        score = MulticlassF1Score(num_classes=3)(pre_y,targetTS.reshape(-1))\n",
    "        score_total += score.item()\n",
    "\n",
    "        # 최적화 진행\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # 에포크 당 검증기능\n",
    "    # 모델 검증 모드 설정\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # 검증 데이터셋\n",
    "        val_featureTS = torch.FloatTensor(valDS.featureDF.values)\n",
    "        val_targetTS = torch.FloatTensor(valDS.targetDF.values)\n",
    "        # 추론/평가\n",
    "        pre_val = model(val_featureTS)\n",
    "        # 손실계산\n",
    "        loss_val = crossLoss(pre_val, val_targetTS.reshape(-1).long())\n",
    "        # 성능평가\n",
    "        score_val = MulticlassF1Score(num_classes=3)(pre_val, val_targetTS.reshape(-1))\n",
    "\n",
    "\n",
    "\n",
    "    # 손실값과 성능평가값 저장\n",
    "    LOSS_HISTORY[0].append(loss_total/CNT) \n",
    "    SCORE_HISTORY[0].append(score_total/CNT)\n",
    "    LOSS_HISTORY[1].append(loss_val) \n",
    "    SCORE_HISTORY[1].append(score_val)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0276528663105435, 0.9974947306844923, 0.9820403655370077, 0.9713784721162584, 0.95998082558314, 0.947044226858351, 0.9329726894696554, 0.9179114103317261, 0.9018204874462552, 0.8846118582619561, 0.8661623332235548, 0.8463511334525214, 0.8251092963748508, 0.8024374975098504, 0.77840123573939, 0.7531267868147956, 0.7268027597003512, 0.6996843616167704, 0.6720912125375536, 0.644393159283532, 0.6169817712571886, 0.5902340412139893, 0.5644751257366605, 0.5399504039022658, 0.516812351014879, 0.4951232969760895, 0.4748704830805461, 0.4559868375460307, 0.43837259544266594, 0.4219125476148393, 0.4064892960919274, 0.3919908040099674, 0.37831513418091667, 0.3653721743159824, 0.35308431254492867, 0.3413859291209115, 0.3302227192454868, 0.3195501251353158, 0.30933252970377606, 0.29954150319099426, 0.2901545928584205, 0.2811541226175096, 0.2725258635150062, 0.2642581644985411, 0.2563411709335115, 0.2487659901380539, 0.24152426587210762, 0.2346077263355255, 0.22800799873140123, 0.22171640147765478, 0.2157237711879942, 0.21002061830626595, 0.2045970078971651, 0.19944265484809875, 0.19454698926872677, 0.18989939242601395, 0.18548898895581564, 0.18130500614643097, 0.1773368302318785, 0.17357376548979017, 0.17000557316674125, 0.16662218338913387, 0.16341380940543282, 0.16037114875184166, 0.15748505459891426, 0.15474695091446242, 0.1521486515800158, 0.14968212404184872, 0.14734002326925597, 0.1451153424051073, 0.14300128031108114, 0.14099160788787735, 0.13908029678795072, 0.13726183068421152, 0.1355308840672175, 0.1338824046154817, 0.1323118329875999, 0.13081475802593762, 0.12938703720768294, 0.12802477760447395, 0.1267244029376242, 0.1254824706249767, 0.12429574235445923, 0.12316128404604064, 0.12207625847723749, 0.1210379639847411, 0.12004390690061781, 0.11909185391333368, 0.11817950879534085, 0.11730484271215068, 0.11646589864459303, 0.11566089797351095, 0.11488810367882252, 0.11414585593673918, 0.11343268015318447, 0.11274716299441126, 0.11208791347841422, 0.11145364224082893, 0.11084320396184921, 0.11025543924834993, 0.109689277700252, 0.10914370955692397, 0.10861779977050093, 0.10811063212653, 0.10762136595116721, 0.10714920465317038, 0.10669336695637968, 0.10625311380459203, 0.10582779803209835, 0.10541677702632216, 0.10501942255844672, 0.10463510350220734, 0.1042633442622092, 0.10390355334513718, 0.10355532852311929, 0.10321810624251763, 0.1028914853102631, 0.10257497864464919, 0.10226827249344853, 0.10197086890952455, 0.10168250898520152, 0.10140273337148958, 0.10113132103449768, 0.10086787957698107, 0.1006120845882429, 0.10036371337870757, 0.10012247289220493, 0.09988804585817787, 0.0996602148645454, 0.09943878319528368, 0.09922345696638028, 0.09901409254719813, 0.09881032992982203, 0.098612105473876, 0.09841923612273401, 0.09823135648750597, 0.09804851799789402, 0.09787040824691455, 0.09769693306750721, 0.09752787008053726, 0.09736314219319159, 0.09720257804211643, 0.0970460365836819, 0.09689339415894614, 0.09674447971499628, 0.09659918449405167, 0.09645750725434886, 0.09631914966222313, 0.09618415269586775, 0.09605226386338472, 0.09592361613694164, 0.09579788722718756, 0.09567505788678925, 0.09555511176586151, 0.09543789271265268, 0.09532325632042354, 0.09521127735368079, 0.09510178972656529, 0.09499469559846653, 0.0948899484032558, 0.09478747001331714, 0.09468727450196941, 0.09458914999332693, 0.09449319991593559, 0.09439928514055079, 0.09430725339593159, 0.09421724344914158, 0.0941290390263829, 0.09404267080956036, 0.09395806667291456, 0.09387520271249944, 0.09379397829373677, 0.093714388863494, 0.09363637580018905, 0.09355992042563027, 0.09348491755210692, 0.09341144422069192, 0.0933393649239507, 0.09326859698113468, 0.09319925178877181, 0.09313123378281792, 0.09306442458182573, 0.09299891731805271, 0.09293462118754785, 0.09287146830724345, 0.0928095221105549, 0.09274867208053668, 0.09268892753041452, 0.09263028716668487, 0.0925726013051139, 0.09251596726891068, 0.0924603875933422, 0.09240576795612772, 0.09235202360691296, 0.09229925440417396, 0.09224741885231601, 0.09219639681072699, 0.09214625450678998, 0.09209701956974135, 0.09204854531627563, 0.0920008738628692, 0.09195395652204752, 0.09190783851469557, 0.09186248662364152, 0.09181782830920485, 0.09177393192011449, 0.09173068238629235, 0.09168811716760199, 0.0916462632206579, 0.09160503031065066, 0.0915644337526626, 0.09152449905458424, 0.09148517292406824, 0.09144636967943774, 0.09140824930121501, 0.09137060979588164, 0.09133359800196356, 0.09129711297444171, 0.09126119134533736, 0.09122576424852014, 0.09119084922389852, 0.09115643457820018, 0.09112253940353791, 0.09108912427392271, 0.09105616166359848, 0.09102364795075522, 0.09099160972982645, 0.09096004643167059, 0.09092891361150476, 0.09089813246909115, 0.09086781735014585, 0.0908379749291473, 0.09080844734691912, 0.09077937295660377, 0.09075063870598872, 0.09072230044855839, 0.09069433334904413, 0.09066671984166735, 0.09063950486274229, 0.09061257768836287, 0.09058601931772298, 0.0905598349765771, 0.09053396738858686, 0.09050839006279905, 0.09048320482381517, 0.09045823710039258, 0.09043361890750627, 0.09040927630849183, 0.09038530991205738, 0.09036159647318225, 0.09033810487017035, 0.09031493434061606, 0.09029206835354368, 0.09026946365419361, 0.09024709445010456, 0.09022500722979505, 0.09020315778131287, 0.09018156330825554, 0.09016021928336057, 0.09013910257878403, 0.09011821034881803, 0.09009762817165917, 0.09007722615367836, 0.09005705207689768, 0.09003710112948385, 0.09001737093139026, 0.08999782466950516, 0.0899785495777097, 0.0899594801529828, 0.08994051676967905, 0.0899218291354676, 0.08990333353479703, 0.08988507583530413, 0.08986691778732671, 0.08984895992196268, 0.08983124055278797, 0.08981368563965791, 0.0897962922592544, 0.08977905699672799, 0.0897620197178589, 0.08974519682427247, 0.08972845813776884, 0.08971195380824308, 0.08969552579542829, 0.08967934134933683, 0.08966330806207326, 0.08964735274720523, 0.0896316061520742, 0.08961597281611627, 0.08960051539664467, 0.08958522804702322, 0.08957007855901288, 0.08955503226671782, 0.08954012347385287, 0.08952539026116331, 0.0895107805263251, 0.08949627685878012, 0.08948192660075922, 0.08946765118485524, 0.08945359895005822, 0.08943960171503325, 0.08942569280043244, 0.08941197405672735, 0.08939835680131283, 0.08938486959474783, 0.08937148009944293, 0.08935818552143043, 0.08934502802892691, 0.08933202301462491, 0.08931900661749144, 0.08930616047129863, 0.08929349523451593, 0.08928086096420884, 0.0892683091159496, 0.08925587143231598, 0.08924356002050142, 0.0892313125077635, 0.08921920156313314, 0.08920717642952998, 0.08919528367308278, 0.08918339060619473, 0.08917162774337663, 0.08915997738949955, 0.089148422729017, 0.08913693499440949, 0.08912552629287045, 0.08911422852219807, 0.08910301107809776, 0.08909182224629654, 0.08908075963457425, 0.08906980409907798, 0.0890588643701954, 0.08904804954201812, 0.08903732140445048, 0.0890266601410177, 0.08901601592596206, 0.08900552312843502, 0.08899512824912865, 0.08898473944928911, 0.08897443327845798, 0.08896421043512721, 0.08895405172370374, 0.08894395248757468, 0.0889339485567891, 0.08892395456011097, 0.08891411252423292, 0.08890429025308953, 0.08889450373438497, 0.08888487773947418, 0.08887522652124365, 0.08886564323782092, 0.08885617010916273, 0.08884671946159667, 0.08883735979907215, 0.08882800637123485, 0.0888187776112722, 0.0888095588888973, 0.08880037796269688, 0.08879134860924548, 0.08878225000161263, 0.08877333755501443, 0.0887643589069032, 0.08875551299812894, 0.0887467399912162, 0.0887379764010095, 0.08872923216161628, 0.08872058038185868, 0.08871194896184736, 0.08870343452629943, 0.08869488244979745, 0.08868647687551048, 0.08867804504310091, 0.0886697171566387, 0.08866139232284492, 0.088653147375832, 0.08864489321907361, 0.08863670420315531, 0.08862858938260211, 0.08862059149477217, 0.0886124690166778, 0.08860447314671344, 0.08859651437443164, 0.08858865535714561, 0.08858076382117967, 0.08857291315992673, 0.08856513837559356, 0.08855745253256625, 0.0885497285829236, 0.0885420389369958, 0.08853445065000819, 0.08852689475235012, 0.08851929883369142, 0.08851183477478723, 0.08850438279720645, 0.08849694652275907, 0.08848952993543611, 0.08848214954034322, 0.08847490667055051, 0.08846758150806029, 0.0884603430620498, 0.08845315570943058, 0.08844596468326119, 0.08843882521614432, 0.08843177060286204, 0.08842464678713845, 0.0884176302028613, 0.08841055083192056, 0.08840365544892848, 0.08839672775421706, 0.08838981803920534, 0.0883829368588825, 0.0883760755467746, 0.08836929707063569, 0.08836249171549247, 0.0883557072116269, 0.08834902784373197, 0.08834233339358535, 0.0883356395125803, 0.08832904411893752, 0.08832245436497033, 0.08831586259313756, 0.08830930310715404, 0.08830283377836975, 0.08829637707418038, 0.08828981140524977, 0.08828337847565611, 0.08827709331591096, 0.08827066478422946, 0.0882642839052197, 0.0882579753589299, 0.08825170610927874, 0.08824540157285002, 0.08823915863306159, 0.08823295796497001, 0.08822679905117387, 0.08822059587368535, 0.08821435319259763, 0.08820833110560973, 0.08820225179402365, 0.08819617369833092, 0.08819010729591052, 0.08818406803119513, 0.08817810021961729, 0.08817210485641327, 0.08816614884158804, 0.08816020304544105, 0.0881542990811997, 0.08814841511452363, 0.08814253016478485, 0.08813668288187021, 0.08813090534466836, 0.08812508416465586, 0.08811930145343973, 0.08811354036960337, 0.08810782846477297, 0.0881021137142347, 0.08809641226091319, 0.088090719603416, 0.088085084170517, 0.08807942915397386, 0.08807383599277172, 0.08806822366184658, 0.08806262568881114, 0.0880570669606742, 0.08805154970226188, 0.08804603976507981, 0.08804052874135475, 0.08803504570904705, 0.0880295678248836, 0.08802414478527175, 0.08801875105645093, 0.08801332589549322, 0.08800798144915865, 0.08800257669968738, 0.08799722733803922, 0.08799183032371932, 0.08798653466833962, 0.08798129897978571, 0.08797596697695553, 0.08797073136601183, 0.08796545270726913, 0.08796025512533055, 0.08795503676972455, 0.08794981355054511, 0.08794466729482843, 0.08793950963041021, 0.08793430987538563, 0.08792917130308019, 0.08792406325745913, 0.08791895298701194, 0.08791386253303951, 0.08790880226944056, 0.08790375043948491, 0.08789867943980628, 0.08789368382551604, 0.08788865745171076, 0.0878836824817376, 0.08787872820782165, 0.08787367412716979, 0.08786875144061115, 0.08786378446449009, 0.08785890143675108, 0.08785397132548194, 0.08784909116932088, 0.08784422081791693, 0.08783932275966638, 0.08783447864051494, 0.087829588395026, 0.08782478289989133, 0.08781994628306064, 0.08781514355602364, 0.08781036160265406, 0.08780558182237048, 0.08780084819429451, 0.08779608147839706, 0.08779135910380217, 0.08778663675507738, 0.08778189290832314, 0.08777721849684086, 0.08777252861505581, 0.08776786015368998, 0.08776313627863096, 0.08775856014755037, 0.0877538615734213, 0.0877492574767934, 0.08774465281102392, 0.08774006232205364, 0.08773542035164104, 0.0877308728845997, 0.08772628348217243, 0.08772174576814804, 0.08771716886096531, 0.0877126556976388, 0.08770812458048265, 0.08770359555880229, 0.08769913708480696, 0.08769458061498073, 0.08769012312404811, 0.08768569204645853, 0.08768123083023562, 0.08767673362874323, 0.087672303404866, 0.08766789892170992, 0.08766351345305641, 0.08765908801514241, 0.08765466700101064, 0.08765026663119595, 0.08764590447147687, 0.0876415207878583, 0.08763718491213189, 0.0876328648171491, 0.08762852844989134, 0.08762418698622948, 0.08761982397279805, 0.08761554731366535, 0.08761122095812526, 0.08760698434586327, 0.08760267439194852, 0.08759841330659886, 0.08759416919201612, 0.08758992295608753, 0.08758567816888292, 0.08758141359107362, 0.0875771691919201, 0.08757297441156374, 0.0875687912468695, 0.08756455693704386, 0.08756038220599294, 0.08755621748665969, 0.08755205305189723, 0.08754790209544201, 0.0875437352547629, 0.08753961053056021, 0.08753539583024879, 0.0875313151627779, 0.08752715189216866, 0.0875230742773662, 0.0875189585559484, 0.0875149028789666, 0.0875107982299394, 0.08750675287511614, 0.08750264871762031, 0.0874985769753241, 0.08749448833987117, 0.0874904819453756, 0.08748643296874231, 0.08748238458712068, 0.08747836365364492, 0.0874743941757414, 0.08747032918553385, 0.08746634051203728, 0.08746238239109516, 0.08745839519219266, 0.0874543805192742, 0.08745038170470959, 0.08744652900430891, 0.08744252253220314, 0.08743856583411495, 0.0874346211914801, 0.0874307053681049, 0.08742673317384389, 0.08742284366033143, 0.08741893445969456, 0.087415011987711, 0.08741109598324531, 0.08740723109804094, 0.0874033275888198, 0.08739947356904547, 0.08739558131330544, 0.08739172553436624, 0.08738783568454285, 0.08738402644586232, 0.08738019614894357, 0.08737629840874837, 0.08737246860336098, 0.08736868003486759, 0.08736484226149817, 0.08736100712687606, 0.08735722564678225, 0.08735337897410823, 0.0873495919836892, 0.08734581764373514, 0.08734205732535985, 0.08733830166359742, 0.08733450644649565, 0.08733072403507929, 0.08732697711740103, 0.08732326582281126, 0.0873195060218374, 0.08731573602805535, 0.0873120310716331, 0.08730827970430255, 0.08730457495484087, 0.08730085302765171, 0.08729716462807523, 0.08729344823708136, 0.08728970238007605, 0.08728606936832269, 0.08728233525632983, 0.08727868348877463, 0.08727499071715607, 0.08727134624496102, 0.08726769502067731, 0.08726402765346898, 0.08726034023695523, 0.08725668420083821, 0.0872530803963956, 0.08724942785273823, 0.08724578669191235, 0.08724216304512487, 0.08723854245100585, 0.08723495641930236, 0.08723131616392897, 0.08722771750763059, 0.08722410678294384, 0.08722049109120336, 0.08721688547585574, 0.0872132822793598, 0.087209718922774, 0.08720617507222211, 0.08720261150867575, 0.08719900425057858, 0.08719546230147696, 0.08719192490550792, 0.0871883640712541, 0.08718482958566812, 0.0871812672380151, 0.08717775766530798, 0.08717422299863149, 0.08717070184906738, 0.0871671416874354, 0.0871636673885708, 0.08716012565936479, 0.08715662057511508, 0.08715309665745331, 0.0871495873046418, 0.08714613710374881, 0.08714263859049727, 0.08713914130607413, 0.08713568880274478, 0.08713218107974778, 0.08712869230657816, 0.08712526382361022, 0.08712176061494069, 0.08711832629827161, 0.0871148759033531, 0.08711140972769095, 0.08710798218898061, 0.08710458209841615, 0.08710109089345981, 0.08709764355120973, 0.0870942151070469, 0.08709082579136723, 0.0870874057808477, 0.08708397270594206, 0.08708053198643029, 0.08707720964836578, 0.08707377099845973, 0.08707039501880193, 0.08706695489430179, 0.08706354503778534, 0.08706017362419516, 0.08705682853340274, 0.08705338144985338, 0.08705003324171735, 0.0870466557615954, 0.08704328702555762, 0.08703994132681853, 0.08703659217442489, 0.08703328526785804, 0.08702987819237427, 0.0870265483778591, 0.0870231884247106, 0.08701985396651758, 0.0870165111652265, 0.08701319431161715, 0.08700984449953669, 0.08700648995323314, 0.08700318343471736, 0.08699985803104937, 0.08699657841740797, 0.08699324547261414, 0.08698991233379477, 0.08698664666412191, 0.0869833581123708, 0.08698000187157756, 0.08697674829616314, 0.08697346616018978, 0.08697015753326316, 0.08696688485280094, 0.08696362677599406, 0.08696033054083172, 0.08695707474059115, 0.08695377225780652, 0.0869505259518822, 0.08694724174630311, 0.08694402314722538, 0.0869407557313227, 0.08693746066031356, 0.08693429519836274, 0.08693102021546413, 0.08692778112728977, 0.08692452474497259, 0.08692127391178575, 0.08691805391572416, 0.08691481339176083, 0.0869115900196549, 0.08690838184621599, 0.08690513100009412, 0.08690192948819862, 0.08689873604776545, 0.08689549355767667, 0.08689228303006126, 0.08688907594316536, 0.08688589759791891, 0.08688270348486388, 0.08687948978816469, 0.0868763287499961, 0.0868731057530062, 0.08686992576501022, 0.08686672863809185, 0.08686359517741948, 0.08686041299046741, 0.08685722246041729, 0.086854047788721, 0.08685088142131765, 0.08684774066528513, 0.08684457760925095, 0.08684144223419328, 0.0868382142830847, 0.08683509268384013, 0.08683192424683107, 0.08682880845541756, 0.08682563280065854, 0.0868225129476438, 0.08681938083221515, 0.08681625702107947, 0.086813085544337, 0.08680993969190037, 0.08680684808900373, 0.0868037070095953, 0.08680059538326329, 0.08679747391336907, 0.08679437053958988, 0.08679122239765194, 0.08678810791267703, 0.08678499945542878, 0.08678188974348207, 0.08677880766077174, 0.0867757461577033, 0.08677261701733288, 0.0867694835178554, 0.08676641995811628, 0.08676334672297041, 0.0867602425860241, 0.08675717213191092, 0.08675408525030232, 0.08675097340407471, 0.08674793894816604, 0.08674485101881954, 0.08674180648651802, 0.08673872392521137, 0.08673566141321014, 0.08673257724795905, 0.08672954411142403, 0.08672644359628773, 0.08672339008707139, 0.08672039699740708, 0.08671731675147182, 0.08671427510368328, 0.08671123512451434, 0.08670814216343893, 0.08670511596008307, 0.08670207757192354, 0.08669906301009986, 0.08669600212791313, 0.0866929260858645, 0.08668993214248782, 0.08668690352028029, 0.0866838801626323, 0.08668085632638799, 0.08667785651050508, 0.08667483943928447, 0.0866718325867421, 0.08666883375392193, 0.08666576697335888, 0.08666276918827659, 0.08665975322946906, 0.0866567730748405, 0.08665376350594063, 0.0866507900128555, 0.08664779062382877, 0.08664480542453627, 0.0866417942258219, 0.08663876441359106, 0.0866358164542665, 0.08663279899499482, 0.08662977108421425, 0.08662684238515794, 0.08662387591579722, 0.08662088656435823, 0.08661792635555482, 0.08661492524616834, 0.08661194159908013, 0.0866089809504855, 0.08660601426122917, 0.0866030707127518, 0.08660010240661602, 0.08659715347716378, 0.08659417365884615, 0.08659121135456695, 0.08658823559785055, 0.08658531515134706, 0.08658240030571404, 0.08657940968664156, 0.0865765157698964, 0.08657351151729624, 0.08657057818749712, 0.08656770152608967, 0.0865647146711126, 0.08656176199049999, 0.08655883600780119, 0.08655594218160129, 0.08655292208358231, 0.08655002873597874, 0.08654713324115922, 0.08654417000555743, 0.08654123985777712, 0.08653834195704097, 0.08653536949875867, 0.08653250401322213, 0.0865295822861501, 0.08652668210884763, 0.08652374418711083, 0.08652083998701225, 0.08651796965083729, 0.08651507105160919, 0.08651213315574245, 0.08650925763261814, 0.08650637552556065, 0.08650344897372027, 0.08650055734647645, 0.08649762424950798, 0.08649470613131093, 0.08649185866427918, 0.08648896432067785, 0.08648608014401463, 0.08648318256665435, 0.08648030696591984, 0.08647740324441758, 0.08647458966717952, 0.08647168832572384, 0.08646882425010619, 0.0864659499687453, 0.08646306561099158, 0.08646016630033652, 0.08645732764206412, 0.08645446513158579, 0.08645159024227825, 0.0864487419474042, 0.0864458585727132, 0.08644301607273519, 0.0864401788631868, 0.08643731211001675, 0.08643444185145199, 0.08643160007583599, 0.08642873294754988, 0.08642588372135328, 0.08642303878958854, 0.08642015630741501, 0.08641731498452525, 0.0864144543884322, 0.08641168666589591, 0.08640881071591543, 0.08640597799482445, 0.0864031141391024, 0.08640029211528599, 0.08639746465875457, 0.08639462817356819, 0.08639183731025292, 0.08638894993863586, 0.0863861607439402, 0.08638331140132828, 0.08638049830268654, 0.08637767374360313, 0.08637481978318344, 0.08637202105536643, 0.08636925004733105, 0.08636639630680697, 0.08636362595845842, 0.08636080824200892, 0.08635796224957125, 0.08635518340290421, 0.08635237749614236, 0.08634955866727978, 0.08634676043099414, 0.08634396961941901, 0.08634119250604676, 0.08633835248959561, 0.0863355467768593, 0.08633276771029665, 0.08632997812754992, 0.08632716289462729, 0.08632435625056839, 0.08632160837037696, 0.08631882764812973, 0.08631608063458568, 0.0863132160415666, 0.08631040807813406, 0.08630765705472893, 0.08630488784466353, 0.0863021221011877, 0.08629931572876456, 0.08629657320367794, 0.08629380533885625, 0.08629103881927828, 0.08628823097226107, 0.0862854720455491, 0.08628270211112168, 0.08627993707907283, 0.08627713880398208, 0.08627438705621494, 0.08627160385044085, 0.08626890772332747, 0.08626611299243653, 0.08626338666201466, 0.08626058012143606, 0.08625784856525974, 0.08625507200809403, 0.08625228329199469, 0.08624957357015875, 0.08624680834408435, 0.08624405820026165, 0.08624130640075439, 0.08623855744695498, 0.0862358305344565, 0.08623313216958195, 0.08623034884739253, 0.08622764122103238, 0.08622485924408668, 0.08622217929870304, 0.08621938939258042, 0.08621662388193524, 0.08621391760081881, 0.08621122204284701, 0.08620848131573035, 0.08620573613896138, 0.08620299288951275, 0.08620032721147355, 0.0861975319761162, 0.08619480246367554, 0.08619207415419321, 0.08618940411704695, 0.08618667325936258, 0.08618394060370822, 0.08618116922055681, 0.08617849776055664, 0.08617579052224755, 0.08617309109670007, 0.08617037224272887]\n"
     ]
    }
   ],
   "source": [
    "print(LOSS_HISTORY[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TORCH_38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
